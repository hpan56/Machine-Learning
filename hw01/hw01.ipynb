{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAT 479: Machine Learning (Fall 2019)  \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
    "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat479-fs2019/\n",
    "\n",
    "---\n",
    "\n",
    "**Due**: Oct 04, (before 11:59 pm).\n",
    "\n",
    "**How to submit**\n",
    "\n",
    "As mentioned in the lecture, you need to send the `.ipynb` file with your answers plus an `.html` file, which will serve as a backup for us in case the `.ipynb` file cannot be opened on my or the TA's computer. In addition, you may also export the notebook as PDF and upload it as well.\n",
    "\n",
    "The homework solution should be uploaded on Canvas. You can submit it as often as you like before the deadline.\n",
    "\n",
    "Note that there are 22 tasks, and the HW is worth 66 pts in total (22*3pts=66pts).\n",
    "\n",
    "**Important**\n",
    "\n",
    "- Please make sure that you provide an answer in each cell and place that contains the **[ your answer ]** tags.\n",
    "- The places that require your code answer are marked with `\"# YOUR CODE\"` comments.\n",
    "- Note that you may use 1 or more line of code for replacing each `\"# YOUR CODE\"` comment.\n",
    "\n",
    "For example, imagine there is a question asking you to implement a threshold function that should return 1 if the input `x` is greater than 0.5 and otherwise. This could appear as follows in the the exercise:\n",
    "\n",
    "```python\n",
    "def threshold_func(x):\n",
    "    # YOUR CODE\n",
    "```\n",
    "\n",
    "A valid answer could be\n",
    "\n",
    "```python\n",
    "def threshold_func(x):\n",
    "    if x > 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "```\n",
    "\n",
    "Another valid solution could be\n",
    "\n",
    "```python\n",
    "def threshold_func(x):\n",
    "    return int(x > 0.5)\n",
    "```\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark  -d -u -a '<Your Name>' -v -p numpy,scipy,matplotlib,sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The watermark package that is being used in the next code cell provides a helper function of the same name, `%watermark` for showing information about your computational environment. This is useful for keeping track of what software versions are/were being used. If you encounter issues with the code, please make sure that your software package have the same version as the the ones shown in the pre-executed watermark cell.\n",
    "\n",
    "Before you execute the watermark cell, you need to install watermark first. If you have not done this yet. To install the watermark package, simply run \n",
    "\n",
    "    !pip install watermark\n",
    "    \n",
    "or \n",
    "\n",
    "    !conda install watermark -c conda-forge\n",
    "    \n",
    "in the a new code cell. Alternatively, you can run either of the two commands (the latter only if you have installed Anaconda or Miniconda) in your command line terminal (e.g., a Linux shell, the Terminal app on macOS, or Cygwin, Putty, etc. on Windows).\n",
    "\n",
    "For more information installing Python, please refer to the previous lectures and ask the TA for help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 1) [3 pts]\n",
    "\n",
    "Choose 3 machine learning application examples from the first lecture (see section 1.2 in the lecture notes, https://github.com/rasbt/stat479-machine-learning-fs19/blob/master/01_overview/01-ml-overview__notes.pdf) and answer the following questions:\n",
    "\n",
    "- What is the overall goal?\n",
    "- How would an appropriate dataset look like?\n",
    "- Which general machine learning category (supervised, unsupervised, reinforcement learning) does this problem fit in?\n",
    "- How would you evaluate the performance of your model (in very general, non technical terms)\n",
    "\n",
    "\n",
    "**Example -- Email Spam classification:**\n",
    "\n",
    "- **Goal.** A potential goal would be to learn how to classify emails as spam or non-spam.\n",
    "- **Dataset.** The dataset is a set consisting of emails as text data and their spam and non-spam labels.\n",
    "- **Category.** Since we are working with class labels (spam, non-spam), this is a supervised learning problem.\n",
    "- **Measure Performance.** Predict class labels in the test dataset and count the number of correct predictions to asses the prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1: [ your answer ]**\n",
    "\n",
    "- **Goal.**  [ your answer ]\n",
    "- **Dataset.** [ your answer ]\n",
    "- **Category.**  [ your answer ]\n",
    "- **Measure Performance.** [ your answer ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2: [ your answer ]**\n",
    "\n",
    "- **Goal.**  [ your answer ]\n",
    "- **Dataset.** [ your answer ]\n",
    "- **Category.**  [ your answer ]\n",
    "- **Measure Performance.** [ your answer ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 3: [ your answer ]**\n",
    "\n",
    "- **Goal.**  [ your answer ]\n",
    "- **Dataset.** [ your answer ]\n",
    "- **Category.**  [ your answer ]\n",
    "- **Measure Performance.** [ your answer ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 2)  [3 pts]\n",
    "\n",
    "\n",
    "\n",
    "If you think about the task of training a machine learning classifier that detects skin cancer based on some features derived from images. After model training, you find that your classifier predicts skin cancer with 95% accuracy. Do you think that the classification accuracy is a good evaluation metric for judging how useful classifier is? What are some potential pitfalls for using this classifier on new patients? (Hint: think about false positives and false negatives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ your answer ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 3)  [3 pts]\n",
    "\n",
    "In the example E 2), cancer classification is a supervised machine learning problem.\n",
    "List 2 examples of unsupervised learning tasks that would fall into the category of clustering. In one or more sentences, explain why you would describe these examples as clustering tasks and not supervised learning tasks. Select examples that are not already that are in the \"Lecture note list\" from E 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ your answer ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 4)  [3 pts]\n",
    "\n",
    "In the *k*-nearest neighbor (*k*-NN) algorithm, what computation happens at training and what computation happens at test time? Explain your answer in 1-2 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ your answer ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 5)   [3 pts]\n",
    "\n",
    "Assume that you are using a *k*-NN classifier on an image dataset with has images with 200x200*3=120,000 features. Would you expect that this classifier would perform better or worse (in terms of prediction accuracy) when you reduce the number of features by downscaling the image (assuming the number of training examples is fixed)? Explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ your answer ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 6)    [3 pts]\n",
    "\n",
    "If your dataset contains several noisy examples (or outliers), is it better to increase or decrease *k*? Explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ your answer ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 7)  [3 pts]\n",
    "\n",
    "Implement the Kronecker Delta function in Python,\n",
    "\n",
    "$$\n",
    "\\delta(i, j) =\n",
    "    \\begin{cases}\n",
    "            1, &         \\text{if } i=j,\\\\\n",
    "            0, &         \\text{if } i\\neq j.\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "The `assert` statements are here to help you: They will raise an `AssertionError` if your function returns unexpected results based on the test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example implementing a Dirac Delta Function\n",
    "\n",
    "def dirac_delta(x):\n",
    "    if x > 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "assert dirac_delta(1) == 1\n",
    "assert dirac_delta(2) == 1\n",
    "assert dirac_delta(-1) == 0\n",
    "assert dirac_delta(0.5) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kronecker_delta(i, j):\n",
    "    # YOUR CODE BELOW\n",
    "    \n",
    "# DO NOT EDIT THE LINES BELOW\n",
    "assert kronecker_delta(1, 0) == 0\n",
    "assert kronecker_delta(2, 2) == 1\n",
    "assert kronecker_delta(-1, 1) == 0\n",
    "assert kronecker_delta(0.5, 0.1) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 8)  [3 pts]\n",
    "\n",
    "Suppose `y_true` is a list that contains true class labels, and `y_pred` is an array with predicted class labels from some machine learning task. Calculate the prediction error **in percent** (**without** using any external libraries like NumPy or scikit-learn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [1, 2, 0, 1, 1, 2, 3, 1, 2, 1]\n",
    "y_pred = [1, 2, 1, 1, 1, 0, 3, 1, 2, 1]\n",
    "\n",
    "\n",
    "correct = 0\n",
    "total_elements = 0\n",
    "for i, j in zip(y_true, y_pred):\n",
    "    # YOUR CODE BELOW\n",
    "        \n",
    "error =     # YOUR CODE\n",
    "        \n",
    "print('Error: %.2f%%' % (error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 9)   [3 pts]\n",
    "\n",
    "Import the NumPy library to create a 3x3 matrix with values ranging 0-8. The expected output should look as follows:\n",
    "\n",
    "```python\n",
    "array([[10, 11, 12],\n",
    "       [13, 14, 15],\n",
    "       [16, 17, 18]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = # YOUR CODE\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 10)  [3 pts]\n",
    "\n",
    "Use create a 2x2 NumPy array with random values drawn from a uniform distribution using the random seed `123` and show the results below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(123)\n",
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 11)  [3 pts]\n",
    "\n",
    "Given an array `A`,\n",
    "\n",
    "```python\n",
    "array([[ 1,  2,  3,  4],\n",
    "       [ 5,  6,  7,  8],\n",
    "       [ 9, 10, 11, 12],\n",
    "       [13, 14, 15, 16]])\n",
    "```\n",
    "\n",
    "use the NumPy slicing syntax to only select the 2x2 lower-right corner of this matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10, 11, 12],\n",
    "    [13, 14, 15, 16]])\n",
    "\n",
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 12)  [3 pts]\n",
    "\n",
    "Given the array `A` below, find the least frequent integer in that array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(123)\n",
    "A = rng.randint(0, 10, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 13)  [3 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the line of code below to read in the `'train_data.txt'` dataset, which consists of 3 columns: 2 feature columns and 1 class label column. The columns are separated via commas and show the first 5 lines of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(# YOUR CODE)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 14)  [3 pts]\n",
    "\n",
    "Consider the following code below, which plots one the samples from class 0 in a 2D scatterplot using matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[['x1', 'x2']].values\n",
    "y_train = df_train['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.scatter(X_train[y_train == 0, 0],\n",
    "            X_train[y_train == 0, 1], \n",
    "            label='class 0',)\n",
    "\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.xlim([-20, 20])\n",
    "plt.ylim([-20, 20])\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the following code below is identical to the code in the previous code cell but contains partial code to also include the examples from the second class. Complete the second `plt.scatter` function to also plot the training examples from `class 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train[y_train == 0, 0],\n",
    "            X_train[y_train == 0, 1], \n",
    "            label='class 0',)\n",
    "\n",
    "plt.scatter(# YOUR CODE )\n",
    "\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.xlim([-20, 20])\n",
    "plt.ylim([-20, 20])\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 15)  [3 pts]\n",
    "\n",
    "Consider the we trained a 3-nearest neighbor classifier using scikit-learn on the previous training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "plot_decision_regions(X_train, y_train, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute *the number of* misclassifications of the 3-NN classifier on the training set. The number of errors should be a count, i.e., a positive integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 16)  [3 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code from E 15) to \n",
    "\n",
    "- also visualize the decision boundaries of *k*-nearest neighbor classifiers with k=1, k=5, k=7, k=9\n",
    "- compute the prediction error on the training set for the *k*-nearest neighbor classifiers with k=1, k=5, k=7, k=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(# YOUR CODE)\n",
    "knn.fit(X_train, y_train)\n",
    "plot_decision_regions(# YOUR CODE)\n",
    "print('Errors:', # YOUR CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(# YOUR CODE)\n",
    "knn.fit(X_train, y_train)\n",
    "plot_decision_regions(# YOUR CODE)\n",
    "print('Errors:', # YOUR CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(# YOUR CODE)\n",
    "knn.fit(X_train, y_train)\n",
    "plot_decision_regions(# YOUR CODE)\n",
    "print('Errors:', # YOUR CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(# YOUR CODE)\n",
    "knn.fit(X_train, y_train)\n",
    "plot_decision_regions(# YOUR CODE)\n",
    "print('Errors:', # YOUR CODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 17)  [3 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a similar approach you used in E 13), now load the `test_data.txt` file into a pandas array. However, note that the dataset now has whitespaces separating the columns instead of commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(# YOUR CODE)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test[['x1', 'x2']].values\n",
    "y_test = df_test['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 18)  [3 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `train_test_split` function from scikit-learn to divide the training dataset further into a training subset and a validation set. The validation set should be 20% of the training dataset size, and the training subset should be 80% of the training dataset size. \n",
    "\n",
    "For you reference, the `train_test_split` function is documented at http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train_sub, X_val, y_train_sub, y_val = train_test_split(X_train, y_train,\n",
    "                                                          # YOUR CODE,\n",
    "                                                          # YOUR CODE,\n",
    "                                                          stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 19)  [3 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a for loop to evaluate different *k* nn models with k=1 to k=14. In particular, fit the `KNeighborsClassifier` on the training subset, then evaluate it on the training subset, validation subset, and test subset. Report the respective classification error or accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1, 15):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_sub, y_train_sub)\n",
    "    # YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 20)  [3 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following code cell, where I implemented *k*-nearest neighbor classification algorithm following the the scikit-learn API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class KNNClassifier(object):\n",
    "    def __init__(self, k, dist_fn=None):\n",
    "        self.k = k\n",
    "        if dist_fn is None:\n",
    "            self.dist_fn = self._euclidean_dist\n",
    "    \n",
    "    def _euclidean_dist(self, a, b):\n",
    "        dist = 0.\n",
    "        for ele_i, ele_j in zip(a, b):\n",
    "            dist += ((ele_i - ele_j)**2)\n",
    "        dist = dist**0.5\n",
    "        return dist\n",
    "        \n",
    "    def _find_nearest(self, x):\n",
    "        dist_idx_pairs = []\n",
    "        for j in range(self.dataset_.shape[0]):\n",
    "            d = self.dist_fn(x, self.dataset_[j])\n",
    "            dist_idx_pairs.append((d, j))\n",
    "            \n",
    "        sorted_dist_idx_pairs = sorted(dist_idx_pairs)\n",
    "\n",
    "        return sorted_dist_idx_pairs\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.dataset_ = X.copy()\n",
    "        self.labels_ = y.copy()\n",
    "        self.possible_labels_ = np.unique(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros(X.shape[0], dtype=int)\n",
    "        for i in range(X.shape[0]):\n",
    "            k_nearest = self._find_nearest(X[i])[:self.k]\n",
    "            indices = [entry[1] for entry in k_nearest]\n",
    "            k_labels = self.labels_[indices]\n",
    "            counts = np.bincount(k_labels,\n",
    "                                 minlength=self.possible_labels_.shape[0])\n",
    "            pred_label = np.argmax(counts)\n",
    "            predictions[i] = pred_label\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_test_inputs = X_train[:5]\n",
    "five_test_labels = y_train[:5]\n",
    "\n",
    "knn = KNNClassifier(k=1)\n",
    "knn.fit(five_test_inputs, five_test_labels)\n",
    "print('True labels:', five_test_labels)\n",
    "print('Pred labels:', knn.predict(five_test_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a very simple implementation of *k*NN, it is relatively slow -- very slow compared to the scikit-learn implementation which uses data structures such as Ball-tree and KD-tree to find the nearest neighbors more efficiently, as discussed in the lecture.\n",
    "\n",
    "While we won't implement advanced data structures in this class, there is already an obvious opportunity for improving the computational efficiency by replacing for-loops with vectorized NumPy code (as discussed in the lecture). In particular, consider the `_euclidean_dist` method in the `KNNClassifier` class above. Below, I have written is as a function (as opposed to a method), for simplicity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(a, b):\n",
    "    dist = 0.\n",
    "    for ele_i, ele_j in zip(a, b):\n",
    "        dist += ((ele_i - ele_j)**2)\n",
    "    dist = dist**0.5\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is now to benchmark this function using the `%timeit` magic command that we talked about in class using two random vectors, `a` and `b` as function inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(123)\n",
    "\n",
    "a = rng.rand(100)\n",
    "b = rng.rand(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 21)  [3 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, rewrite the Euclidean distance function from E 20) in NumPy using \n",
    "- either using the `np.sqrt` and `np.sum` function\n",
    "- or using the `np.linalg.norm` function\n",
    "\n",
    "and benchmark it again using the `%timeit` magic command. Then, compare results with the results you got in E 22). Did you make the function faster? Yes or No? Explain why, in 1-2 sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit # YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ Your answer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E 22)  [3 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another inefficient aspect of the `KNNClassifier` implementation is that it uses the sorted function to sort all values in the distance value array. Since we are only interested in the *k* nearest neighbors, sorting *all* neighbors is quite unnecessary.\n",
    "\n",
    "Consider the array `c`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(123)\n",
    "c = rng.rand(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the sorted function to select the 3 smallest values in that array, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(c)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, use the `%timeit` magic command to benchmark the sorted command above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit sorted(c)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more efficient way to select the *k* smallest values from an array is to use a priority queue, for example, implemented using a heap data structure. A convenient `nsmallest` function that does exactly that is available from Python's standard library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nsmallest\n",
    "\n",
    "nsmallest(3, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, use the `%timeit` magic command to benchmark the `nsmallest` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit nsmallest(3, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize your findings in 1-3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Your Answer]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PS: There are many other options for performing the same task, for example, using NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit np.sort(c)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit c[np.argpartition(c, 3)[:3]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
